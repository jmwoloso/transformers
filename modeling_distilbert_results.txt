============================= test session starts ==============================
platform linux -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /home/jason/.virtualenvs/hf_dev/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/home/jason/source/python/transformers/.hypothesis/examples')
rootdir: /home/jason/source/python/transformers, configfile: setup.cfg
plugins: timeout-1.4.2, forked-1.3.0, xdist-2.3.0, hypothesis-6.39.4, dash-1.21.0
collecting ... collected 6 items

src/transformers/models/distilbert/modeling_distilbert.py::transformers.models.distilbert.modeling_distilbert.DistilBertForMaskedLM.forward PASSED
src/transformers/models/distilbert/modeling_distilbert.py::transformers.models.distilbert.modeling_distilbert.DistilBertForMultipleChoice.forward PASSED
src/transformers/models/distilbert/modeling_distilbert.py::transformers.models.distilbert.modeling_distilbert.DistilBertForQuestionAnswering.forward FAILED
src/transformers/models/distilbert/modeling_distilbert.py::transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification.forward FAILED
src/transformers/models/distilbert/modeling_distilbert.py::transformers.models.distilbert.modeling_distilbert.DistilBertForTokenClassification.forward PASSED
src/transformers/models/distilbert/modeling_distilbert.py::transformers.models.distilbert.modeling_distilbert.DistilBertModel.forward PASSED

=================================== FAILURES ===================================
_ [doctest] transformers.models.distilbert.modeling_distilbert.DistilBertForQuestionAnswering.forward _
940     >>> model = DistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")
941 
942     >>> question, text = "Who was Jim Henson?", "Jim Henson was a nice puppet"
943     >>> inputs = tokenizer(question, text, return_tensors="pt")
944     >>> start_positions = torch.tensor([1])
945     >>> end_positions = torch.tensor([3])
946 
947     >>> outputs = model(**inputs, start_positions=start_positions, end_positions=end_positions)
948     >>> loss = outputs.loss
949     >>> round(loss.item(), 2)
Expected nothing
Got:
    2.71

/home/jason/source/python/transformers/src/transformers/models/distilbert/modeling_distilbert.py:949: DocTestFailure
944     >>> start_positions = torch.tensor([1])
945     >>> end_positions = torch.tensor([3])
946 
947     >>> outputs = model(**inputs, start_positions=start_positions, end_positions=end_positions)
948     >>> loss = outputs.loss
949     >>> round(loss.item(), 2)
950     
951 
952     >>> start_scores = outputs.start_logits
953     >>> list(start_scores.shape)
Expected nothing
Got:
    [1, 14]

/home/jason/source/python/transformers/src/transformers/models/distilbert/modeling_distilbert.py:953: DocTestFailure
948     >>> loss = outputs.loss
949     >>> round(loss.item(), 2)
950     
951 
952     >>> start_scores = outputs.start_logits
953     >>> list(start_scores.shape)
954     
955 
956     >>> end_scores = outputs.end_logits
957     >>> list(end_scores.shape)
Expected nothing
Got:
    [1, 14]

/home/jason/source/python/transformers/src/transformers/models/distilbert/modeling_distilbert.py:957: DocTestFailure
_ [doctest] transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification.forward _
816 
817     >>> tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")
818     >>> model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=2)
819 
820     >>> inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
821     >>> labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1
822     >>> outputs = model(**inputs, labels=labels)
823     >>> loss = outputs.loss
824     >>> logits = outputs.logits
825     >>> list(logits.shape)
Expected nothing
Got:
    [1, 2]

/home/jason/source/python/transformers/src/transformers/models/distilbert/modeling_distilbert.py:825: DocTestFailure
836     >>> torch.manual_seed(0)  # doctest: +IGNORE_RESULT
837 
838     >>> tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")
839     >>> model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased", problem_type="multi_label_classification", num_labels=2)
840 
841     >>> inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
842     >>> labels = torch.tensor([[1, 1]], dtype=torch.float)  # need dtype=float for BCEWithLogitsLoss
843     >>> outputs = model(**inputs, labels=labels)
844     >>> loss = outputs.loss
845     >>> list(logits.shape)
Expected nothing
Got:
    [1, 2]

/home/jason/source/python/transformers/src/transformers/models/distilbert/modeling_distilbert.py:845: DocTestFailure
=============================== warnings summary ===============================
../../../.virtualenvs/hf_dev/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:585
  /home/jason/.virtualenvs/hf_dev/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:585: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    np.object,

../../../.virtualenvs/hf_dev/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:627
  /home/jason/.virtualenvs/hf_dev/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:627: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    np.object,

../../../.virtualenvs/hf_dev/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:637
  /home/jason/.virtualenvs/hf_dev/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:637: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    np.bool,

../../../.virtualenvs/hf_dev/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:108
  /home/jason/.virtualenvs/hf_dev/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:108: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    np.object:

../../../.virtualenvs/hf_dev/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:110
  /home/jason/.virtualenvs/hf_dev/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:110: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    np.bool:

../../../.virtualenvs/hf_dev/lib/python3.8/site-packages/tensorflow/python/ops/numpy_ops/np_random.py:110
  /home/jason/.virtualenvs/hf_dev/lib/python3.8/site-packages/tensorflow/python/ops/numpy_ops/np_random.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
    def randint(low, high=None, size=None, dtype=onp.int):  # pylint: disable=missing-function-docstring

src/transformers/dynamic_module_utils.py:81
  /home/jason/source/python/transformers/src/transformers/dynamic_module_utils.py:81: DeprecationWarning: invalid escape sequence \s
    relative_imports = re.findall("^\s*import\s+\.(\S+)\s*$", content, flags=re.MULTILINE)

src/transformers/dynamic_module_utils.py:83
  /home/jason/source/python/transformers/src/transformers/dynamic_module_utils.py:83: DeprecationWarning: invalid escape sequence \s
    relative_imports += re.findall("^\s*from\s+\.(\S+)\s+import", content, flags=re.MULTILINE)

src/transformers/dynamic_module_utils.py:125
  /home/jason/source/python/transformers/src/transformers/dynamic_module_utils.py:125: DeprecationWarning: invalid escape sequence \s
    imports = re.findall("^\s*import\s+(\S+)\s*$", content, flags=re.MULTILINE)

src/transformers/dynamic_module_utils.py:127
  /home/jason/source/python/transformers/src/transformers/dynamic_module_utils.py:127: DeprecationWarning: invalid escape sequence \s
    imports += re.findall("^\s*from\s+(\S+)\s+import", content, flags=re.MULTILINE)

-- Docs: https://docs.pytest.org/en/stable/warnings.html
=========================== short test summary info ============================
FAILED src/transformers/models/distilbert/modeling_distilbert.py::transformers.models.distilbert.modeling_distilbert.DistilBertForQuestionAnswering.forward
FAILED src/transformers/models/distilbert/modeling_distilbert.py::transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification.forward
================== 2 failed, 4 passed, 10 warnings in 29.53s ===================
